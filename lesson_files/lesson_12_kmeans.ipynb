{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fa00ae3",
   "metadata": {},
   "source": [
    "# Lesson 12 — Unsupervised Learning: k‑Means Clustering\n",
    "\n",
    "The k‑means algorithm partitions a set of data points into \\(k\\) clusters by iteratively\n",
    "assigning points to the nearest cluster centroid and updating centroids as the mean\n",
    "of assigned points.  It is a simple yet widely used unsupervised learning method.\n",
    "In this notebook we implement k‑means from scratch and apply it to synthetic data.\n",
    "\n",
    "## Outline\n",
    "\n",
    "- **Data generation**: create synthetic clusters for visualization.\n",
    "- **k‑means algorithm**: initialization, assignment step, update step.\n",
    "- **Convergence criteria**: detect when cluster assignments stop changing.\n",
    "- **Visualization**: plot data colored by cluster and centroid trajectories.\n",
    "- **Exercises & interview summary**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085f251e",
   "metadata": {},
   "source": [
    "### Imports & Data Generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74db377",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs  # datasets only\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# Generate synthetic data with 3 clusters\n",
    "n_samples = 400\n",
    "centers = [(-5, -2), (0, 0), (5, 5)]\n",
    "cluster_std = [1.0, 1.5, 0.5]\n",
    "X, y_true = make_blobs(n_samples=n_samples, centers=centers, cluster_std=cluster_std, random_state=42)\n",
    "\n",
    "print(f\"Generated {n_samples} data points for k‑means clustering.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60968827",
   "metadata": {},
   "source": [
    "### k‑Means Algorithm Implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09532bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_centroids(X: np.ndarray, k: int) -> np.ndarray:\n",
    "    \"\"\"Randomly select k data points as initial centroids.\"\"\"\n",
    "    indices = np.random.choice(X.shape[0], size=k, replace=False)\n",
    "    return X[indices].copy()\n",
    "\n",
    "def assign_clusters(X: np.ndarray, centroids: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Assign each point to the nearest centroid.\"\"\"\n",
    "    distances = np.linalg.norm(X[:, np.newaxis, :] - centroids[np.newaxis, :, :], axis=2)\n",
    "    return np.argmin(distances, axis=1)\n",
    "\n",
    "def update_centroids(X: np.ndarray, labels: np.ndarray, k: int) -> np.ndarray:\n",
    "    \"\"\"Compute new centroids as the mean of assigned points.\"\"\"\n",
    "    centroids = np.zeros((k, X.shape[1]))\n",
    "    for i in range(k):\n",
    "        points = X[labels == i]\n",
    "        if len(points) > 0:\n",
    "            centroids[i] = points.mean(axis=0)\n",
    "    return centroids\n",
    "\n",
    "def kmeans(X: np.ndarray, k: int, max_iters: int = 100) -> tuple[np.ndarray, np.ndarray, list]:\n",
    "    \"\"\"Run the k‑means clustering algorithm.\"\"\"\n",
    "    centroids = initialize_centroids(X, k)\n",
    "    history = [centroids.copy()]\n",
    "    for iteration in range(max_iters):\n",
    "        labels = assign_clusters(X, centroids)\n",
    "        new_centroids = update_centroids(X, labels, k)\n",
    "        history.append(new_centroids.copy())\n",
    "        # Check for convergence\n",
    "        if np.allclose(new_centroids, centroids):\n",
    "            break\n",
    "        centroids = new_centroids\n",
    "    return centroids, labels, history\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dec12d9",
   "metadata": {},
   "source": [
    "### Running k‑Means and Visualizing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f0ba1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3\n",
    "centroids, labels, history = kmeans(X, k)\n",
    "\n",
    "print(f\"k‑Means converged in {len(history) - 1} iterations.\")\n",
    "\n",
    "# Plot final clustering\n",
    "plt.figure(figsize=(6, 5))\n",
    "for i in range(k):\n",
    "    pts = X[labels == i]\n",
    "    plt.scatter(pts[:, 0], pts[:, 1], label=f\"Cluster {i}\", alpha=0.6)\n",
    "plt.scatter(centroids[:, 0], centroids[:, 1], color='black', marker='x', s=100, label=\"Centroids\")\n",
    "plt.xlabel(\"X1\")\n",
    "plt.ylabel(\"X2\")\n",
    "plt.title(\"k‑Means Clustering Results\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot centroid trajectory for each cluster\n",
    "plt.figure(figsize=(6, 5))\n",
    "for j in range(k):\n",
    "    traj = np.array([c[j] for c in history])\n",
    "    plt.plot(traj[:, 0], traj[:, 1], marker='o', label=f\"Centroid {j} path\")\n",
    "plt.xlabel(\"X1\")\n",
    "plt.ylabel(\"X2\")\n",
    "plt.title(\"Centroid Trajectories During k‑Means\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8f2fcd",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "1. **Initialization**: Experiment with different initialization strategies (e.g., k‑means++).\n",
    "   How does initialization affect convergence and cluster quality?\n",
    "2. **Different k Values**: Vary k and use criteria like the elbow method to choose the\n",
    "   number of clusters.  Plot the within‑cluster sum of squares as a function of k.\n",
    "3. **High‑Dimensional Data**: Apply k‑means to the digits dataset using PCA to reduce\n",
    "   dimensionality first.  Visualize the clusters in the reduced space.\n",
    "4. **Spectral Clustering**: Implement spectral clustering and compare it to k‑means\n",
    "   on datasets with non‑convex clusters.\n",
    "\n",
    "### Interview‑Ready Summary\n",
    "\n",
    "- The k‑means algorithm partitions data into k clusters by iteratively assigning\n",
    "  points to the nearest centroid and updating centroids to the mean of assigned\n",
    "  points.  It optimizes the sum of squared distances within clusters.\n",
    "- Convergence is guaranteed but the solution can depend on initialization; the\n",
    "  algorithm may converge to a local optimum.  k‑means++ is a common initialization\n",
    "  strategy that improves cluster quality.\n",
    "- Choosing the number of clusters k requires domain knowledge or heuristics such as\n",
    "  the elbow method or silhouette scores.\n",
    "- k‑means assumes spherical, equally sized clusters and uses Euclidean distance.\n",
    "  Variants like k‑medoids or Gaussian mixtures can handle different shapes and\n",
    "  distributions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
